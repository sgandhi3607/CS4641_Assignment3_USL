{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from textwrap import wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 25\n",
    "\n",
    "\n",
    "columns = ['Radius','Texture','Perimeter','Area','Smoothness','Compactness',\n",
    "           'Concavity','Concave_Points','Symmetry','Fractal_Dimension',\n",
    "           'Malignant/Benign']\n",
    "\n",
    "# Read CSV file into pandas df\n",
    "df = pd.read_csv('../datasets/breast_cancer/breast-cancer-wisconsin.csv',\n",
    "                 delimiter=',', quotechar='\"', names=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe without Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing dataframe head (without any preprocessing)....\n",
      "    Radius  Texture  Perimeter  Area  Smoothness  Compactness Concavity  \\\n",
      "0  1000025        5          1     1           1            2         1   \n",
      "1  1002945        5          4     4           5            7        10   \n",
      "2  1015425        3          1     1           1            2         2   \n",
      "3  1016277        6          8     8           1            3         4   \n",
      "4  1017023        4          1     1           3            2         1   \n",
      "5  1017122        8         10    10           8            7        10   \n",
      "6  1018099        1          1     1           1            2        10   \n",
      "7  1018561        2          1     2           1            2         1   \n",
      "8  1033078        2          1     1           1            2         1   \n",
      "9  1033078        4          2     1           1            2         1   \n",
      "\n",
      "   Concave_Points  Symmetry  Fractal_Dimension  Malignant/Benign  \n",
      "0               3         1                  1                 2  \n",
      "1               3         2                  1                 2  \n",
      "2               3         1                  1                 2  \n",
      "3               3         7                  1                 2  \n",
      "4               3         1                  1                 2  \n",
      "5               9         7                  1                 4  \n",
      "6               3         1                  1                 2  \n",
      "7               3         1                  1                 2  \n",
      "8               1         1                  5                 2  \n",
      "9               2         1                  1                 2  \n"
     ]
    }
   ],
   "source": [
    "print(\"Printing dataframe head (without any preprocessing)....\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saksham/.local/lib/python3.5/site-packages/ipykernel_launcher.py:19: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "# Shuffle\n",
    "df = shuffle(df, random_state=RANDOM_SEED)\n",
    "\n",
    "# DROP USELESS ROWS AND COLUMNS\n",
    "df.dropna(inplace=True)\n",
    "cols = [0]\n",
    "# Drop ID column (it's not attribute or target)\n",
    "df.drop(df.columns[cols],axis=1,inplace=True)\n",
    "# Drop all data points with missing variables  (denoted by '?' entry)\n",
    "nostrings_row_list = [x.isdigit() for x in df.iloc[:,5]]\n",
    "df = df[nostrings_row_list]\n",
    "\n",
    "\n",
    "# Handle categorical data\n",
    "# df = pd.get_dummies(df)\n",
    "\n",
    "\n",
    "# Split data into X and y vectors\n",
    "X = df.ix[:, df.columns != 'Malignant/Benign']\n",
    "y = df['Malignant/Benign']\n",
    "\n",
    "# Change 2 -> 0 (benign) and 4 -> 1 (malignant)\n",
    "y.replace(2, 0, inplace=True)\n",
    "y.replace(4, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check on Dataframe \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check: Printing out dataframe and shape after preprocessing... \n",
      "     Texture  Perimeter  Area  Smoothness  Compactness Concavity  \\\n",
      "437        4          1     1           1            2         1   \n",
      "511        5          1     1           1            2         1   \n",
      "215        8          7     8           7            5         5   \n",
      "684        1          1     1           1            2         1   \n",
      "302       10         10    10           7            9        10   \n",
      "341        1          1     1           1            2         1   \n",
      "608        5         10    10          10           10        10   \n",
      "366        6         10    10          10            8        10   \n",
      "205        5         10    10           9            6        10   \n",
      "270        8          4     7           1            3        10   \n",
      "\n",
      "     Concave_Points  Symmetry  Fractal_Dimension  Malignant/Benign  \n",
      "437               1         1                  1                 0  \n",
      "511               2         1                  1                 0  \n",
      "215               5        10                  2                 1  \n",
      "684               1         1                  1                 0  \n",
      "302               7        10                 10                 1  \n",
      "341               3         1                  1                 0  \n",
      "608              10         1                  1                 1  \n",
      "366               7        10                  7                 1  \n",
      "205               7        10                  5                 1  \n",
      "270               3         9                  2                 1  \n",
      "df.shape:  (683, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Sanity Check: Printing out dataframe and shape after preprocessing... \")\n",
    "print(df.head(10))\n",
    "print(\"df.shape: \", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Split, Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split into 30%  training data, 70% testing data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "#                                                     test_size=0.30, random_state=RANDOM_SEED)\n",
    "\n",
    "\n",
    "# # Apply scaling. Large values of certain features undesireable for NN\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check on X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICA - (Followed by Clustering Later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saksham/.local/lib/python3.5/site-packages/sklearn/decomposition/fastica_.py:299: UserWarning: Ignoring n_components with whiten=False.\n",
      "  warnings.warn('Ignoring n_components with whiten=False.')\n",
      "/home/saksham/.local/lib/python3.5/site-packages/sklearn/decomposition/fastica_.py:121: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "/home/saksham/.local/lib/python3.5/site-packages/sklearn/decomposition/fastica_.py:299: UserWarning: Ignoring n_components with whiten=False.\n",
      "  warnings.warn('Ignoring n_components with whiten=False.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kur1:  7.0973433558415735\n",
      "Printing error without ICA ...  0.03953147877013177\n",
      "Printing error_dimReduced ...  0.03953147877013177\n",
      "kur1:  7.195489326455472\n",
      "Printing error without ICA ...  0.03953147877013177\n",
      "Printing error_dimReduced ...  0.03953147877013177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saksham/.local/lib/python3.5/site-packages/sklearn/decomposition/fastica_.py:121: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "/home/saksham/.local/lib/python3.5/site-packages/sklearn/decomposition/fastica_.py:299: UserWarning: Ignoring n_components with whiten=False.\n",
      "  warnings.warn('Ignoring n_components with whiten=False.')\n",
      "/home/saksham/.local/lib/python3.5/site-packages/sklearn/decomposition/fastica_.py:121: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "/home/saksham/.local/lib/python3.5/site-packages/sklearn/decomposition/fastica_.py:299: UserWarning: Ignoring n_components with whiten=False.\n",
      "  warnings.warn('Ignoring n_components with whiten=False.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kur1:  7.253598631374575\n",
      "Printing error without ICA ...  0.03953147877013177\n",
      "Printing error_dimReduced ...  0.03953147877013177\n",
      "kur1:  8.13078943991839\n",
      "Printing error without ICA ...  0.03953147877013177\n",
      "Printing error_dimReduced ...  0.03953147877013177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saksham/.local/lib/python3.5/site-packages/sklearn/decomposition/fastica_.py:121: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "/home/saksham/.local/lib/python3.5/site-packages/sklearn/decomposition/fastica_.py:299: UserWarning: Ignoring n_components with whiten=False.\n",
      "  warnings.warn('Ignoring n_components with whiten=False.')\n",
      "/home/saksham/.local/lib/python3.5/site-packages/sklearn/decomposition/fastica_.py:121: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "/home/saksham/.local/lib/python3.5/site-packages/sklearn/decomposition/fastica_.py:299: UserWarning: Ignoring n_components with whiten=False.\n",
      "  warnings.warn('Ignoring n_components with whiten=False.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kur1:  7.1311024960235105\n",
      "Printing error without ICA ...  0.03953147877013177\n",
      "Printing error_dimReduced ...  0.03953147877013177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saksham/.local/lib/python3.5/site-packages/sklearn/decomposition/fastica_.py:121: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "/home/saksham/.local/lib/python3.5/site-packages/sklearn/decomposition/fastica_.py:299: UserWarning: Ignoring n_components with whiten=False.\n",
      "  warnings.warn('Ignoring n_components with whiten=False.')\n",
      "/home/saksham/.local/lib/python3.5/site-packages/sklearn/decomposition/fastica_.py:121: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kur1:  7.363833525221575\n",
      "Printing error without ICA ...  0.03953147877013177\n",
      "Printing error_dimReduced ...  0.03953147877013177\n",
      "kur1:  7.896025802812462\n",
      "Printing error without ICA ...  0.03953147877013177\n",
      "Printing error_dimReduced ...  0.03953147877013177\n",
      "kur1:  9.253116128395776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saksham/.local/lib/python3.5/site-packages/sklearn/decomposition/fastica_.py:299: UserWarning: Ignoring n_components with whiten=False.\n",
      "  warnings.warn('Ignoring n_components with whiten=False.')\n",
      "/home/saksham/.local/lib/python3.5/site-packages/sklearn/decomposition/fastica_.py:121: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing error without ICA ...  0.03953147877013177\n",
      "Printing error_dimReduced ...  0.03953147877013177\n",
      "kur1:  7.88480094893176\n",
      "Printing error without ICA ...  0.03953147877013177\n",
      "Printing error_dimReduced ...  0.03953147877013177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saksham/.local/lib/python3.5/site-packages/sklearn/decomposition/fastica_.py:299: UserWarning: Ignoring n_components with whiten=False.\n",
      "  warnings.warn('Ignoring n_components with whiten=False.')\n",
      "/home/saksham/.local/lib/python3.5/site-packages/sklearn/decomposition/fastica_.py:121: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "n_comp_max = 10 \n",
    "\n",
    "n_comp_list = [x for x in range(1, n_comp_max)]\n",
    "\n",
    "errorlist = []\n",
    "errorlist_dimReduced = []\n",
    "kurtosis_list = [] \n",
    "\n",
    "for n_comp in n_comp_list: \n",
    "    \n",
    "    algs = ['parallel','deflation']\n",
    "    alg = algs[0]\n",
    "    ica = FastICA(n_components=n_comp,whiten=False,algorithm=alg)\n",
    "#     kur0 = sum(kurtosis(X))\n",
    "    ica = ica.fit(X)\n",
    "    x_dimReduced_ICA = ica.transform(X)\n",
    "    kurtosis(x_dimReduced_ICA)\n",
    "    kur1 = sum(kurtosis(x_dimReduced_ICA))\n",
    "#     print(ica.components_)\n",
    "#     print(\"kur0: \", kur0)\n",
    "    print(\"kur1: \", kur1)\n",
    "    kurtosis_list.append(kur1)\n",
    "\n",
    "    # Without ICA\n",
    "    clf = KMeans(n_clusters=2, random_state=0)\n",
    "    clf.fit(X)\n",
    "    error = mean_squared_error(y, clf.predict(X))\n",
    "    errorlist.append(error)\n",
    "    print(\"Printing error without ICA ... \", error)\n",
    "    \n",
    "    # After PCA\n",
    "    clf_dimReduced = KMeans(n_clusters=2, random_state=0)\n",
    "    clf_dimReduced.fit(x_dimReduced_ICA)\n",
    "    error_dimReduced = mean_squared_error(y, clf_dimReduced.predict(x_dimReduced_ICA))\n",
    "    errorlist_dimReduced.append(error_dimReduced)\n",
    "    print(\"Printing error_dimReduced ... \", error_dimReduced)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03953147877013177\n",
      "0.03953147877013177\n"
     ]
    }
   ],
   "source": [
    "print(min(errorlist))\n",
    "print(min(errorlist_dimReduced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering after ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_dimReduced = KMeans(n_clusters=2, random_state=0)\n",
    "# clf_dimReduced.fit(X_dim_reduced)\n",
    "# error_dimReduced = mean_squared_error(y, clf_dimReduced.predict(X_dim_reduced))\n",
    "# print(\"Printing error_dimReduced ... \", error_dimReduced)\n",
    "\n",
    "\n",
    "# Hyperparameters \n",
    "\n",
    "# Vary this as needed \n",
    "init_method = \"k-means++\"\n",
    "# Number of times to run algo with different centroid seeds \n",
    "n_init = 1\n",
    "max_iter = 10 \n",
    "# Runs each of the n_inits in parallel using specified number of threads\n",
    "n_jobs = 1\n",
    "\n",
    "\n",
    "# k means determine k\n",
    "distortions = []\n",
    "K = range(1,31)\n",
    "\n",
    "for k in K:\n",
    "    print(\"clustering after pca for k-value: \", k)\n",
    "    kmeanModel = KMeans(n_clusters=k).fit(X_dim_reduced)\n",
    "    kmeanModel.fit(X_dim_reduced)\n",
    "    \n",
    "    clf_kMeans = KMeans(n_clusters=k, random_state=0)\n",
    "    clf_kMeans.fit(X)\n",
    "    distortions.append(sum(np.min(cdist(X_dim_reduced, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / X.shape[0])\n",
    "\n",
    "    \n",
    "# Plot the elbow\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing varying k on WBCD (after PCA)')\n",
    "plt.xlabel('Number of cluster centers')\n",
    "plt.ylabel('Sum of Squared Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare clustering with k = 2 (Dim reduced k-means, vs just k-means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for n_comp in n_comp_list: \n",
    "#     n_comp = 9\n",
    "    \n",
    "#     ica = FastICA(n_components=n_comp,whiten=True,algorithm=alg)\n",
    "# #     kur0 = sum(kurtosis(X))\n",
    "#     ica = ica.fit(X)\n",
    "#     x_dimReduced_ICA = ica.transform(X)\n",
    "#     kur1 = sum(kurtosis(x_dimReduced_ICA))\n",
    "# #     print(ica.components_)\n",
    "# #     print(\"kur0: \", kur0)\n",
    "#     print(\"kur1: \", kur1)\n",
    "\n",
    "errorlist = []\n",
    "errorlist_dimReduced = []\n",
    "\n",
    "n_comp_list = range(1, 10)\n",
    "\n",
    "algs = ['parallel','deflation']\n",
    "alg = algs[0]\n",
    "\n",
    "\n",
    "for n_comp in n_comp_list: \n",
    "    ica = FastICA(n_components=n_comp,whiten=True,algorithm=alg)\n",
    "    ica = ica.fit(X)\n",
    "    X_dim_reduced = ica.transform(X)\n",
    "\n",
    "    # Without ICA\n",
    "    clf = KMeans(n_clusters=2, random_state=0)\n",
    "    clf.fit(X)\n",
    "    error = mean_squared_error(y, clf.predict(X))\n",
    "    errorlist.append(error)\n",
    "    print(\"Printing error without PCA ... \", error)\n",
    "    \n",
    "    # After ICA\n",
    "    clf_dimReduced = KMeans(n_clusters=2, random_state=0)\n",
    "    clf_dimReduced.fit(X_dim_reduced)\n",
    "    error_dimReduced = mean_squared_error(y, clf_dimReduced.predict(X_dim_reduced))\n",
    "    errorlist_dimReduced.append(error_dimReduced)\n",
    "    print(\"Printing error_dimReduced ... \", error_dimReduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(errorlist))\n",
    "print(min(errorlist_dimReduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the elbow\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing varying k on WBCD (after PCA)')\n",
    "plt.xlabel('Number of cluster centers')\n",
    "plt.ylabel('Sum of Squared Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM Clustering after PCA (when k = 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorlist = []\n",
    "errorlist_dimReduced = []\n",
    "\n",
    "for n_comp in range(1,10): \n",
    "    \n",
    "    pca = PCA(n_components=n_comp)\n",
    "    X_dim_reduced = pca.fit(X).transform(X)\n",
    "    print(pca.explained_variance_ratio_)\n",
    "\n",
    "    # Without PCA\n",
    "    fitter = GaussianMixture(n_components=2,covariance_type='full',n_init=10,max_iter=200).fit(X)\n",
    "    fitter.fit(X)\n",
    "    error = mean_squared_error(y, fitter.predict(X))\n",
    "    errorlist.append(error)\n",
    "    print(\"Printing error without PCA ... \", error)\n",
    "    \n",
    "    # After PCA\n",
    "    fitter_dimReduced= GaussianMixture(n_components=2,covariance_type='full',n_init=10,max_iter=200).fit(X)\n",
    "    fitter_dimReduced.fit(X_dim_reduced)\n",
    "    error_dimReduced = mean_squared_error(y, fitter_dimReduced.predict(X_dim_reduced))\n",
    "    errorlist_dimReduced.append(error_dimReduced)\n",
    "    print(\"Printing error_dimReduced ... \", error_dimReduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(errorlist))\n",
    "print(min(errorlist_dimReduced))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
