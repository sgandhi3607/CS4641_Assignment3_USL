{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WBCD Dataset Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "from textwrap import wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import more Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 25\n",
    "\n",
    "df = pd.read_csv('../datasets/us_income/adult-train.csv', delimiter=',', quotechar='\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe without Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing dataframe head (without any preprocessing)....\n",
      "   Age     Workclass  Fnlwgt      Education  EducationNum  \\\n",
      "0   34   Federal-gov   67083      Bachelors            13   \n",
      "1   72   Federal-gov   39110           11th             7   \n",
      "2   45   Federal-gov  235891     Assoc-acdm            12   \n",
      "3   26   Federal-gov  206983    Prof-school            15   \n",
      "4   31   Federal-gov  139455      Bachelors            13   \n",
      "5   27   Federal-gov  196386     Assoc-acdm            12   \n",
      "6   19   Federal-gov  255921   Some-college            10   \n",
      "7   60   Federal-gov   27466   Some-college            10   \n",
      "8   59   Federal-gov  212448        HS-grad             9   \n",
      "9   32   Federal-gov  148138      Bachelors            13   \n",
      "\n",
      "         MaritalStatus          Occupation    Relationship  \\\n",
      "0        Never-married     Exec-managerial       Unmarried   \n",
      "1             Divorced        Adm-clerical   Not-in-family   \n",
      "2        Never-married        Adm-clerical   Not-in-family   \n",
      "3   Married-civ-spouse      Prof-specialty         Husband   \n",
      "4        Never-married     Exec-managerial       Own-child   \n",
      "5   Married-civ-spouse        Adm-clerical         Husband   \n",
      "6        Never-married   Handlers-cleaners       Own-child   \n",
      "7              Widowed     Exec-managerial   Not-in-family   \n",
      "8              Widowed               Sales       Unmarried   \n",
      "9   Married-civ-spouse      Prof-specialty         Husband   \n",
      "\n",
      "                  Race      Sex  CapitalGain  CapitalLoss  HoursPerWeek  \\\n",
      "0   Asian-Pac-Islander     Male         1471            0            40   \n",
      "1                White   Female            0            0             8   \n",
      "2                White     Male            0            0            40   \n",
      "3                White     Male            0            0            60   \n",
      "4                White   Female            0            0            40   \n",
      "5                White     Male         4064            0            40   \n",
      "6                White     Male            0            0            20   \n",
      "7                White   Female            0            0            40   \n",
      "8                White   Female            0            0            40   \n",
      "9   Asian-Pac-Islander     Male            0         2002            40   \n",
      "\n",
      "   NativeCountry  Income  \n",
      "0       Cambodia   <=50K  \n",
      "1         Canada   <=50K  \n",
      "2       Columbia   <=50K  \n",
      "3       Columbia   <=50K  \n",
      "4           Cuba   <=50K  \n",
      "5    El-Salvador   <=50K  \n",
      "6        England   <=50K  \n",
      "7        England   <=50K  \n",
      "8        Germany   <=50K  \n",
      "9           Iran   <=50K  \n"
     ]
    }
   ],
   "source": [
    "print(\"Printing dataframe head (without any preprocessing)....\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(' <=50K', 0, inplace=True)\n",
    "df.replace(' >50K', 1, inplace=True)\n",
    "\n",
    "df = pd.get_dummies(df)\n",
    "# print(df.head(5))\n",
    "\n",
    "X = df.loc[:, df.columns != 'Income']\n",
    "y = df['Income']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Age    Fnlwgt  EducationNum  CapitalGain  CapitalLoss  HoursPerWeek  \\\n",
      "0 -0.337877 -1.161452      1.128900     0.051171    -0.218582     -0.077733   \n",
      "1  2.555231 -1.426215     -1.224046    -0.147442    -0.218582     -2.748855   \n",
      "2  0.499601  0.436307      0.736742    -0.147442    -0.218582     -0.077733   \n",
      "3 -0.946952  0.162695      1.913215    -0.147442    -0.218582      1.591718   \n",
      "4 -0.566280 -0.476455      1.128900    -0.147442    -0.218582     -0.077733   \n",
      "5 -0.870818  0.062395      0.736742     0.401276    -0.218582     -0.077733   \n",
      "6 -1.479893  0.625890     -0.047573    -0.147442    -0.218582     -1.747184   \n",
      "7  1.641618 -1.536425     -0.047573    -0.147442    -0.218582     -0.077733   \n",
      "8  1.565483  0.214421     -0.439731    -0.147442    -0.218582     -0.077733   \n",
      "9 -0.490146 -0.394270      1.128900    -0.147442     4.733206     -0.077733   \n",
      "\n",
      "     Income  Workclass_ Federal-gov  Workclass_ Local-gov  Workclass_ Private  \\\n",
      "0 -0.575682                5.566339             -0.271237           -1.682116   \n",
      "1 -0.575682                5.566339             -0.271237           -1.682116   \n",
      "2 -0.575682                5.566339             -0.271237           -1.682116   \n",
      "3 -0.575682                5.566339             -0.271237           -1.682116   \n",
      "4 -0.575682                5.566339             -0.271237           -1.682116   \n",
      "5 -0.575682                5.566339             -0.271237           -1.682116   \n",
      "6 -0.575682                5.566339             -0.271237           -1.682116   \n",
      "7 -0.575682                5.566339             -0.271237           -1.682116   \n",
      "8 -0.575682                5.566339             -0.271237           -1.682116   \n",
      "9 -0.575682                5.566339             -0.271237           -1.682116   \n",
      "\n",
      "   ...   NativeCountry_ Portugal   NativeCountry_ Puerto-Rico  \\\n",
      "0  ...                 -0.033593                    -0.060223   \n",
      "1  ...                 -0.033593                    -0.060223   \n",
      "2  ...                 -0.033593                    -0.060223   \n",
      "3  ...                 -0.033593                    -0.060223   \n",
      "4  ...                 -0.033593                    -0.060223   \n",
      "5  ...                 -0.033593                    -0.060223   \n",
      "6  ...                 -0.033593                    -0.060223   \n",
      "7  ...                 -0.033593                    -0.060223   \n",
      "8  ...                 -0.033593                    -0.060223   \n",
      "9  ...                 -0.033593                    -0.060223   \n",
      "\n",
      "    NativeCountry_ Scotland   NativeCountry_ South   NativeCountry_ Taiwan  \\\n",
      "0                   -0.0191              -0.048574               -0.037341   \n",
      "1                   -0.0191              -0.048574               -0.037341   \n",
      "2                   -0.0191              -0.048574               -0.037341   \n",
      "3                   -0.0191              -0.048574               -0.037341   \n",
      "4                   -0.0191              -0.048574               -0.037341   \n",
      "5                   -0.0191              -0.048574               -0.037341   \n",
      "6                   -0.0191              -0.048574               -0.037341   \n",
      "7                   -0.0191              -0.048574               -0.037341   \n",
      "8                   -0.0191              -0.048574               -0.037341   \n",
      "9                   -0.0191              -0.048574               -0.037341   \n",
      "\n",
      "    NativeCountry_ Thailand   NativeCountry_ Trinadad&Tobago  \\\n",
      "0                 -0.023747                        -0.024436   \n",
      "1                 -0.023747                        -0.024436   \n",
      "2                 -0.023747                        -0.024436   \n",
      "3                 -0.023747                        -0.024436   \n",
      "4                 -0.023747                        -0.024436   \n",
      "5                 -0.023747                        -0.024436   \n",
      "6                 -0.023747                        -0.024436   \n",
      "7                 -0.023747                        -0.024436   \n",
      "8                 -0.023747                        -0.024436   \n",
      "9                 -0.023747                        -0.024436   \n",
      "\n",
      "    NativeCountry_ United-States   NativeCountry_ Vietnam  \\\n",
      "0                       -3.21672                -0.046112   \n",
      "1                       -3.21672                -0.046112   \n",
      "2                       -3.21672                -0.046112   \n",
      "3                       -3.21672                -0.046112   \n",
      "4                       -3.21672                -0.046112   \n",
      "5                       -3.21672                -0.046112   \n",
      "6                       -3.21672                -0.046112   \n",
      "7                       -3.21672                -0.046112   \n",
      "8                       -3.21672                -0.046112   \n",
      "9                       -3.21672                -0.046112   \n",
      "\n",
      "    NativeCountry_ Yugoslavia  \n",
      "0                   -0.023038  \n",
      "1                   -0.023038  \n",
      "2                   -0.023038  \n",
      "3                   -0.023038  \n",
      "4                   -0.023038  \n",
      "5                   -0.023038  \n",
      "6                   -0.023038  \n",
      "7                   -0.023038  \n",
      "8                   -0.023038  \n",
      "9                   -0.023038  \n",
      "\n",
      "[10 rows x 105 columns]\n"
     ]
    }
   ],
   "source": [
    "normalized_df=(df-df.mean())/df.std()\n",
    "print(normalized_df.head(10))\n",
    "# X_normalized = normalized_df.loc[:, normalized_df.columns != 'Income']\n",
    "X = normalized_df.loc[:, normalized_df.columns != 'Income']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split into 30%  training data, 70% testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.30, random_state=RANDOM_SEED)\n",
    "\n",
    "\n",
    "# # Apply scaling. Large values of certain features undesireable for NN\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21113, 104)\n",
      "(9049, 104)\n",
      "(21113,)\n",
      "(9049,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_set_max_size: 21113 \n",
      "\n",
      "activation: relu\n",
      "learning a neural net with training_set_size=2111\n",
      "getting data\n",
      "building net\n",
      "training\n",
      "validating\n",
      "train_err: 0.12363808621506395\n",
      "test_err: 0.16295594504973945\n",
      "---\n",
      "activation: relu\n",
      "learning a neural net with training_set_size=4222\n",
      "getting data\n",
      "building net\n",
      "training\n",
      "validating\n",
      "train_err: 0.11203221222169588\n",
      "test_err: 0.17219327333017528\n",
      "---\n",
      "activation: relu\n",
      "learning a neural net with training_set_size=6333\n",
      "getting data\n",
      "building net\n",
      "training\n",
      "validating\n",
      "train_err: 0.1241117953576504\n",
      "test_err: 0.16832464866571925\n",
      "---\n",
      "activation: relu\n",
      "learning a neural net with training_set_size=8444\n",
      "getting data\n",
      "building net\n",
      "training\n",
      "validating\n",
      "train_err: 0.1231643770724775\n",
      "test_err: 0.1607058266224538\n",
      "---\n",
      "activation: relu\n",
      "learning a neural net with training_set_size=10555\n",
      "getting data\n",
      "building net\n",
      "training\n"
     ]
    }
   ],
   "source": [
    "# NNClassifier\n",
    "train_size = len(X_train)\n",
    "offsets = range(int(0.1 * train_size), int(train_size), int(0.1 * train_size))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train_err = [0] * len(offsets)\n",
    "test_err = [0] * len(offsets)\n",
    "\n",
    "print('training_set_max_size:', train_size, '\\n')\n",
    "\n",
    "activation_functions = ['relu', 'logistic', 'tanh']\n",
    "\n",
    "for activation in activation_functions:\n",
    "    for i, o in enumerate(offsets):\n",
    "        print('activation: ' + activation)\n",
    "        print('learning a neural net with training_set_size=' + str(o))\n",
    "        print('getting data'),\n",
    "        X_train_temp = X_train[:o].copy()\n",
    "        y_train_temp = y_train[:o].copy()\n",
    "        X_test_temp = X_test[:o].copy()\n",
    "        y_test_temp = y_test[:o].copy()\n",
    "        print('building net'),\n",
    "        mlp = MLPClassifier(activation=activation, alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "           beta_2=0.999, epsilon=1e-08,\n",
    "           # hidden_layer_sizes=(50, 25, 12),\n",
    "           hidden_layer_sizes=(13, 13, 13),\n",
    "           learning_rate='constant',\n",
    "           learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "           nesterovs_momentum=True, random_state=None,\n",
    "           shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1)\n",
    "        print('training'),\n",
    "        mlp.fit(X_train,y_train)\n",
    "        print('validating')\n",
    "        train_err[i] = mean_squared_error(y_train_temp,\n",
    "                    mlp.predict(X_train_temp))\n",
    "        test_err[i] = mean_squared_error(y_test_temp,\n",
    "                    mlp.predict(X_test_temp))\n",
    "\n",
    "        # print(classification_report(y_train, mlp.predict(X_train)))\n",
    "        # print(classification_report(y_test, mlp.predict(X_test)))\n",
    "\n",
    "        print('train_err: ' + str(train_err[i]))\n",
    "        print('test_err: ' + str(test_err[i]))\n",
    "        print('---')\n",
    "\n",
    "    # Plot results\n",
    "    print('plotting results')\n",
    "    plt.figure()\n",
    "    title = 'WBCD Neural Nets: Performance x Training Set Size using Activation ' + activation\n",
    "    plt.title('\\n'.join(wrap(title,60)))\n",
    "    # plt.subplots_adjust(top=0.85)\n",
    "    plt.plot(offsets, test_err, '-', label='test error')\n",
    "    plt.plot(offsets, train_err, '-', label='train error')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Training Set Size')\n",
    "    plt.ylabel('Mean Square Error')\n",
    "    filename = 'wbcd' + activation + '_PerformancexTrainingSetSize.png'\n",
    "    plt.show()\n",
    "#     plt.savefig('plots/WBCD/NN/' + filename)\n",
    "    print('plot complete')\n",
    "    ### ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
