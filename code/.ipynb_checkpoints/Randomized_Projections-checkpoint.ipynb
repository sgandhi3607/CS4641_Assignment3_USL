{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "from textwrap import wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 25\n",
    "\n",
    "\n",
    "columns = ['Radius','Texture','Perimeter','Area','Smoothness','Compactness',\n",
    "           'Concavity','Concave_Points','Symmetry','Fractal_Dimension',\n",
    "           'Malignant/Benign']\n",
    "\n",
    "# Read CSV file into pandas df\n",
    "df = pd.read_csv('../datasets/breast_cancer/breast-cancer-wisconsin.csv',\n",
    "                 delimiter=',', quotechar='\"', names=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe without Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing dataframe head (without any preprocessing)....\n",
      "    Radius  Texture  Perimeter  Area  Smoothness  Compactness Concavity  \\\n",
      "0  1000025        5          1     1           1            2         1   \n",
      "1  1002945        5          4     4           5            7        10   \n",
      "2  1015425        3          1     1           1            2         2   \n",
      "3  1016277        6          8     8           1            3         4   \n",
      "4  1017023        4          1     1           3            2         1   \n",
      "5  1017122        8         10    10           8            7        10   \n",
      "6  1018099        1          1     1           1            2        10   \n",
      "7  1018561        2          1     2           1            2         1   \n",
      "8  1033078        2          1     1           1            2         1   \n",
      "9  1033078        4          2     1           1            2         1   \n",
      "\n",
      "   Concave_Points  Symmetry  Fractal_Dimension  Malignant/Benign  \n",
      "0               3         1                  1                 2  \n",
      "1               3         2                  1                 2  \n",
      "2               3         1                  1                 2  \n",
      "3               3         7                  1                 2  \n",
      "4               3         1                  1                 2  \n",
      "5               9         7                  1                 4  \n",
      "6               3         1                  1                 2  \n",
      "7               3         1                  1                 2  \n",
      "8               1         1                  5                 2  \n",
      "9               2         1                  1                 2  \n"
     ]
    }
   ],
   "source": [
    "print(\"Printing dataframe head (without any preprocessing)....\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saksham/.local/lib/python3.5/site-packages/ipykernel_launcher.py:19: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "# Shuffle\n",
    "df = shuffle(df, random_state=RANDOM_SEED)\n",
    "\n",
    "# DROP USELESS ROWS AND COLUMNS\n",
    "df.dropna(inplace=True)\n",
    "cols = [0]\n",
    "# Drop ID column (it's not attribute or target)\n",
    "df.drop(df.columns[cols],axis=1,inplace=True)\n",
    "# Drop all data points with missing variables  (denoted by '?' entry)\n",
    "nostrings_row_list = [x.isdigit() for x in df.iloc[:,5]]\n",
    "df = df[nostrings_row_list]\n",
    "\n",
    "\n",
    "# Handle categorical data\n",
    "# df = pd.get_dummies(df)\n",
    "\n",
    "\n",
    "# Split data into X and y vectors\n",
    "X = df.ix[:, df.columns != 'Malignant/Benign']\n",
    "y = df['Malignant/Benign']\n",
    "\n",
    "# Change 2 -> 0 (benign) and 4 -> 1 (malignant)\n",
    "y.replace(2, 0, inplace=True)\n",
    "y.replace(4, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check on Dataframe \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check: Printing out dataframe and shape after preprocessing... \n",
      "     Texture  Perimeter  Area  Smoothness  Compactness Concavity  \\\n",
      "437        4          1     1           1            2         1   \n",
      "511        5          1     1           1            2         1   \n",
      "215        8          7     8           7            5         5   \n",
      "684        1          1     1           1            2         1   \n",
      "302       10         10    10           7            9        10   \n",
      "341        1          1     1           1            2         1   \n",
      "608        5         10    10          10           10        10   \n",
      "366        6         10    10          10            8        10   \n",
      "205        5         10    10           9            6        10   \n",
      "270        8          4     7           1            3        10   \n",
      "\n",
      "     Concave_Points  Symmetry  Fractal_Dimension  Malignant/Benign  \n",
      "437               1         1                  1                 0  \n",
      "511               2         1                  1                 0  \n",
      "215               5        10                  2                 1  \n",
      "684               1         1                  1                 0  \n",
      "302               7        10                 10                 1  \n",
      "341               3         1                  1                 0  \n",
      "608              10         1                  1                 1  \n",
      "366               7        10                  7                 1  \n",
      "205               7        10                  5                 1  \n",
      "270               3         9                  2                 1  \n",
      "df.shape:  (683, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Sanity Check: Printing out dataframe and shape after preprocessing... \")\n",
    "print(df.head(10))\n",
    "print(\"df.shape: \", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Split, Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split into 30%  training data, 70% testing data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "#                                                     test_size=0.30, random_state=RANDOM_SEED)\n",
    "\n",
    "\n",
    "# # Apply scaling. Large values of certain features undesireable for NN\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check on X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Texture  Perimeter  Area  Smoothness  Compactness Concavity  \\\n",
      "437        4          1     1           1            2         1   \n",
      "511        5          1     1           1            2         1   \n",
      "215        8          7     8           7            5         5   \n",
      "684        1          1     1           1            2         1   \n",
      "302       10         10    10           7            9        10   \n",
      "341        1          1     1           1            2         1   \n",
      "608        5         10    10          10           10        10   \n",
      "366        6         10    10          10            8        10   \n",
      "205        5         10    10           9            6        10   \n",
      "270        8          4     7           1            3        10   \n",
      "586        8         10    10          10            6        10   \n",
      "264        7          9     4          10           10         3   \n",
      "554        3          1     1           1            2         1   \n",
      "509        2          1     1           1            2         1   \n",
      "360        6         10    10          10           10        10   \n",
      "527        4          1     1           1            2         1   \n",
      "676        1          1     2           1            2         1   \n",
      "367        5          8     8          10            5        10   \n",
      "519        4          7     8           3            4        10   \n",
      "370        4          3     2           1            3         1   \n",
      "1          5          4     4           5            7        10   \n",
      "484        5          1     2           1            2         1   \n",
      "528        6          1     3           2            2         1   \n",
      "71         6         10     2           8           10         2   \n",
      "353        2          7    10          10            7        10   \n",
      "77         5          3     1           2            2         1   \n",
      "344        7          6     4           8           10        10   \n",
      "466       10          6     6           2            4        10   \n",
      "118        1          1     1           1            4         3   \n",
      "262        8          8     9           4            5        10   \n",
      "..       ...        ...   ...         ...          ...       ...   \n",
      "303        1          1     1           1            2         1   \n",
      "650        3          1     1           2            3         4   \n",
      "160       10          7     7           4            5        10   \n",
      "649        3          1     1           1            2         1   \n",
      "548        3          1     1           1            1         1   \n",
      "562        1          1     1           1            2         1   \n",
      "109        6          5     4           4            3         9   \n",
      "492        4          1     1           1            1         1   \n",
      "656        5          1     1           1            2         1   \n",
      "201       10          8     8           4           10        10   \n",
      "559        5          1     1           1            2         1   \n",
      "304        8          3     4           9            3        10   \n",
      "406        4          2     2           1            2         1   \n",
      "131        2          1     1           1            2         1   \n",
      "259        5          7     7           1            5         8   \n",
      "88         4          1     1           1            2         1   \n",
      "167       10          8    10          10            6         1   \n",
      "641        3          1     1           1            2         1   \n",
      "453        4          5     5           8            6        10   \n",
      "500        6          1     1           1            2         1   \n",
      "253        6         10    10           2            8        10   \n",
      "156        1          2     2           1            2         1   \n",
      "136        4          1     1           1            2         1   \n",
      "151        7          2     4           1            6        10   \n",
      "255        5          6     6           2            4        10   \n",
      "317        6          8     7           8            6         8   \n",
      "143        1          1     1           1            2         5   \n",
      "474        5          1     1           1            2         1   \n",
      "318        1          1     1           1            5         1   \n",
      "132        5         10     8          10            8        10   \n",
      "\n",
      "     Concave_Points  Symmetry  Fractal_Dimension  \n",
      "437               1         1                  1  \n",
      "511               2         1                  1  \n",
      "215               5        10                  2  \n",
      "684               1         1                  1  \n",
      "302               7        10                 10  \n",
      "341               3         1                  1  \n",
      "608              10         1                  1  \n",
      "366               7        10                  7  \n",
      "205               7        10                  5  \n",
      "270               3         9                  2  \n",
      "586              10        10                  1  \n",
      "264               5         3                  3  \n",
      "554               1         1                  1  \n",
      "509               1         1                  1  \n",
      "360               8        10                 10  \n",
      "527               3         1                  1  \n",
      "676               2         1                  1  \n",
      "367               8        10                  3  \n",
      "519               9         1                  1  \n",
      "370               2         1                  1  \n",
      "1                 3         2                  1  \n",
      "484               1         1                  1  \n",
      "528               1         1                  1  \n",
      "71                7         8                 10  \n",
      "353               4         9                  4  \n",
      "77                2         1                  1  \n",
      "344               9         5                  3  \n",
      "466               9         7                  1  \n",
      "118               1         1                  1  \n",
      "262               7         8                  1  \n",
      "..              ...       ...                ...  \n",
      "303               3         1                  1  \n",
      "650               1         1                  1  \n",
      "160               5         7                  2  \n",
      "649               2         1                  1  \n",
      "548               1         1                  1  \n",
      "562               3         1                  1  \n",
      "109               7         8                  3  \n",
      "492               2         1                  1  \n",
      "656               2         1                  1  \n",
      "201               8         1                  1  \n",
      "559               2         1                  1  \n",
      "304               3         3                  1  \n",
      "406               2         1                  1  \n",
      "131               3         1                  1  \n",
      "259               3         4                  1  \n",
      "88                3         1                  1  \n",
      "167               3         1                 10  \n",
      "641               2         1                  1  \n",
      "453              10         7                  1  \n",
      "500               3         1                  1  \n",
      "253               7         3                  3  \n",
      "156               2         1                  1  \n",
      "136               2         1                  1  \n",
      "151               5         4                  3  \n",
      "255               3         6                  1  \n",
      "317               8         9                  1  \n",
      "143               1         1                  1  \n",
      "474               1         1                  1  \n",
      "318               3         1                  1  \n",
      "132               3         6                  3  \n",
      "\n",
      "[683 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Helper Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data_list(data_list): \n",
    "    arr = np.array(data_list)\n",
    "    variance = np.var(arr)\n",
    "    mean = np.mean(arr)\n",
    "    \n",
    "    return mean, variance \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Without Dimensionality Reduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing error (without Dim. Reduc.) ...  0.03953147877013177\n"
     ]
    }
   ],
   "source": [
    "clf = KMeans(n_clusters=2, random_state=0)\n",
    "clf.fit(X)\n",
    "error = mean_squared_error(y, clf.predict(X))\n",
    "print(\"Printing error (without Dim. Reduc.) ... \", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Projections - Followed by Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.42643436 -0.74205514  0.78116886 -0.68258382 -0.74144219 -0.26909874\n",
      "  -0.65571131 -0.85877011  0.84440656]\n",
      " [ 0.78972199  0.42986544  0.46096199  0.28910531  0.30397782 -0.19647131\n",
      "  -0.00592606  0.37053697  0.56878386]\n",
      " [-0.48005542 -0.45890725  0.94084246  0.91607815  0.48496626  0.60216161\n",
      "  -0.32645795 -0.60490595  0.14584035]]\n",
      "[[-1.2826074  -0.30600844  0.51440669  0.19177812 -0.16143588 -0.30928614\n",
      "   0.62831584  0.22866404 -1.36514773]\n",
      " [ 0.54388955  0.36112754 -0.12286517 -0.77350558 -1.57119535 -0.13892799\n",
      "   0.12860376  0.3319936   0.64712882]\n",
      " [-0.2624797   0.17914617 -0.65369974  0.22158144  0.16429531  0.66736404\n",
      "   0.39396168 -0.09101541 -1.02954322]]\n",
      "[[ 1.34134957e-02  1.71811095e-01 -3.17397983e-01 -1.75111789e-01\n",
      "   8.09154454e-02  6.48540588e-01  2.78596331e-01 -2.65994370e-01\n",
      "  -5.62541139e-01]\n",
      " [-8.63015631e-01 -1.70047791e-01 -5.71502467e-01 -1.33069007e-01\n",
      "   2.14822913e-04  6.29413487e-02 -7.45706075e-01 -1.60049780e-01\n",
      "  -3.55174574e-01]\n",
      " [-6.80058103e-01 -6.77747925e-01 -5.11526481e-02 -3.64997565e-01\n",
      "   1.47051542e-01 -1.29434534e+00 -1.65014112e-01 -2.47471380e-01\n",
      "   7.70665975e-01]]\n",
      "[[ 0.25398932  0.73522276  0.12639612  0.52077118 -0.61426835  0.50119746\n",
      "   0.11739805 -0.90632827  0.22348138]\n",
      " [ 0.37292824  1.21382824  0.62549254  0.11809781 -0.46764116  0.01943369\n",
      "   0.56159586  0.55339611  0.53249085]\n",
      " [-0.08589209 -0.16068898  0.17897413  0.69466343 -0.69174767  0.32188405\n",
      "  -0.71722565  0.10152063  0.42589703]]\n",
      "[[ 0.47566135 -0.2515613   1.26883366  0.35868155 -1.07132265  0.55637128\n",
      "  -0.42085679  0.62597946  0.42644507]\n",
      " [ 0.35367991 -0.04757947 -1.25285185 -0.14855751  0.35605532 -0.29946011\n",
      "  -0.98892649 -0.10619759 -0.65580649]\n",
      " [-0.2418209  -0.48571234 -0.52518402  0.82546225  0.12986811 -0.11647564\n",
      "  -0.46832903 -0.37540816 -0.47951861]]\n",
      "[[ 0.51034422  0.18204854  0.11682157 -0.18356473 -0.17873401 -0.35091882\n",
      "   0.97590406  0.61331399  0.14018983]\n",
      " [ 0.90528229 -0.56548526 -0.36025341  0.22528151  0.27861501  0.05117403\n",
      "  -0.28547908 -0.01463379  1.3483264 ]\n",
      " [-0.71726234  0.23766428  0.1822314   0.36446272  0.15253203 -0.51640233\n",
      "   0.27810294  0.49219695 -0.5481525 ]]\n",
      "[[-0.45193095 -0.11302714  0.26390481 -0.52207731  0.04366505 -0.24468807\n",
      "  -1.08076357 -0.52993786  0.65197314]\n",
      " [ 0.8268747   0.37005759 -0.47335709  0.30567375 -0.18602644 -0.7887687\n",
      "   0.65761282 -0.62368754  0.02615507]\n",
      " [ 0.0231562  -0.37482172  0.86302956 -0.11692966 -0.67626398  0.50912858\n",
      "  -0.07375308 -0.0063483  -0.49913778]]\n",
      "[[-1.58922777 -0.13316358 -0.29507063  0.62006827 -0.31337343  0.44846696\n",
      "   0.84828454 -1.01996846  0.22037772]\n",
      " [-0.738962   -0.88423662 -0.45655385 -0.38595737  0.46253414  0.28003915\n",
      "  -0.35572478 -0.74681919 -0.68185531]\n",
      " [-0.07411195  0.74016052  0.43203509 -0.33830402 -0.43307608 -0.57438925\n",
      "  -0.1478626   0.10752748  0.03061041]]\n",
      "[[ 0.03118987  0.14235305  0.3545147  -0.30995583  0.29778298  1.02164554\n",
      "   0.51229656 -0.57675985  0.54292224]\n",
      " [ 0.30566751 -0.0408981  -0.42648635 -0.48367401 -0.50182049  0.13706348\n",
      "  -0.66202497  0.13326794 -1.04074838]\n",
      " [ 0.00904668 -0.61283265  0.67638119  0.2229388  -0.66135839 -0.93769886\n",
      "   0.08075511  0.52392989 -0.29770469]]\n",
      "[[-0.02349326 -0.17202366  0.29481592 -0.38362964 -0.05502859  0.03855911\n",
      "   0.6781882   0.19088705  0.85700172]\n",
      " [ 0.42336955 -0.52529096 -0.25705272 -0.61999135  0.6404976   0.06983586\n",
      "   0.60741886  0.01108038  1.37158307]\n",
      " [ 0.92891832 -0.26001189 -0.14311852 -0.42284424 -0.48749355 -0.00204151\n",
      "   0.10471017  0.45290268 -0.12181159]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-55a4bfc51b83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_data_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Variance: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mean' is not defined"
     ]
    }
   ],
   "source": [
    "# NOTE: Need to run this one multiple times, keep the best runs, since it's random \n",
    "\n",
    "iterations_per_n_comp = 10\n",
    "\n",
    "error_list = list()\n",
    "\n",
    "# Specify number of eignevectors to use for PCA \n",
    "# n_comp = 3\n",
    "\n",
    "\n",
    "# pca = PCA(n_components=n_comp)\n",
    "# X_dim_reduced = pca.fit(X).transform(X)\n",
    "# print(pca.explained_variance_ratio_)\n",
    "\n",
    "# print(\"Printing X_dim_reduced...\")\n",
    "# print(X_dim_reduced)\n",
    "\n",
    "\n",
    "for i in range(iterations_per_n_comp): \n",
    "\n",
    "\n",
    "    rp = GaussianRandomProjection(n_components=n_comp)\n",
    "    rp = rp.fit(X)\n",
    "    X_dim_reduced = rp.transform(X)\n",
    "    print(rp.components_)\n",
    "\n",
    "\n",
    "    clf_dimReduced = KMeans(n_clusters=2, random_state=0)\n",
    "    clf_dimReduced.fit(X_dim_reduced)\n",
    "    error_dimReduced = mean_squared_error(y, clf_dimReduced.predict(X_dim_reduced))\n",
    "#     print(\"Printing error_dimReduced ... \", error_dimReduced)\n",
    "    \n",
    "    error_list.append(error_dimReduced)\n",
    "\n",
    "# Get mean and variance from helper function \n",
    "mean, var = analyze_data_list(error_list)\n",
    "\n",
    "print(\"Mean: \", mean, \"Variance: \", var)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
